2015-04-17 15:44:50,961 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-17 15:44:52,366 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-17 15:44:59,883 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-3] - Bound to /0.0.0.0:7070
2015-04-17 15:44:59,884 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-3] - Bound received. EventServer is ready.
2015-04-17 15:45:16,617 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-17 15:45:27,744 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_5 doesn't exist yet. Creating now...
2015-04-17 15:45:28,059 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 5.
2015-04-17 15:45:28,083 INFO  io.prediction.tools.console.App$ [main] - Created new app:
2015-04-17 15:45:28,083 INFO  io.prediction.tools.console.App$ [main] -       Name: TextApp1
2015-04-17 15:45:28,084 INFO  io.prediction.tools.console.App$ [main] -         ID: 5
2015-04-17 15:45:28,084 INFO  io.prediction.tools.console.App$ [main] - Access Key: IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK
2015-04-17 16:00:13,198 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-17 16:00:13,200 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp1
2015-04-17 16:00:13,201 INFO  io.prediction.tools.console.App$ [main] -       App ID: 5
2015-04-17 16:00:13,201 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-17 16:00:15,699 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-17 16:00:26,782 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_5...
2015-04-17 16:00:32,086 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 5
2015-04-17 16:00:32,227 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_5 doesn't exist yet. Creating now...
2015-04-17 16:00:37,570 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 5.
2015-04-17 16:00:37,672 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-17 22:24:39,857 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [main-EventThread] - This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2015-04-20 01:44:03,926 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-20 01:44:05,592 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-20 01:44:06,430 ERROR io.prediction.data.storage.hbase.StorageClient [main] - HBase master is not running (ZooKeeper ensemble: localhost). Please make sure that HBase is running properly, and that the configuration is pointing at the correct ZooKeeper ensemble.
2015-04-20 01:44:06,431 ERROR io.prediction.data.storage.Storage$ [main] - Error initializing storage client for source HBASE
2015-04-20 01:44:06,431 ERROR io.prediction.data.storage.Storage$ [main] - com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.ipc.ServerNotRunningYetException): org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.56/192.168.1.56:55282 is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-20 01:44:10,443 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-20 01:44:10,584 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-20 01:44:10,593 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-20 01:44:10,601 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-20 01:44:10,611 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-20 01:44:10,622 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-20 01:44:10,623 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-20 01:45:35,019 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-20 01:45:35,022 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp1
2015-04-20 01:45:35,023 INFO  io.prediction.tools.console.App$ [main] -       App ID: 5
2015-04-20 01:45:35,023 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-20 01:45:37,369 INFO  io.prediction.tools.console.App$ [main] - Aborted.
2015-04-20 01:45:41,896 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-20 01:45:41,898 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp1
2015-04-20 01:45:41,898 INFO  io.prediction.tools.console.App$ [main] -       App ID: 5
2015-04-20 01:45:41,899 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-20 01:45:43,735 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-20 01:45:49,759 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_5...
2015-04-20 01:45:56,243 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 5
2015-04-20 01:46:01,473 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_5 doesn't exist yet. Creating now...
2015-04-20 01:46:01,756 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 5.
2015-04-20 01:46:01,860 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-20 01:46:33,030 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-20 01:46:33,083 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-20 01:46:33,102 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-20 01:46:33,115 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-20 01:46:33,125 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-20 01:46:33,136 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-20 01:46:33,137 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-20 02:00:19,046 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-20 02:00:19,097 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-20 02:00:19,114 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-20 02:00:19,121 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-20 02:00:19,126 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-20 02:00:19,134 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-20 02:00:19,135 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-20 02:01:53,889 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-20 02:01:55,672 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-20 02:02:08,254 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-3] - Bound to /0.0.0.0:7070
2015-04-20 02:02:08,255 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-3] - Bound received. EventServer is ready.
2015-04-20 02:43:04,293 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-20 02:43:06,376 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-20 02:43:10,491 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-2] - Bound to /0.0.0.0:7070
2015-04-20 02:43:10,492 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-2] - Bound received. EventServer is ready.
2015-04-20 06:45:43,606 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [main-EventThread] - This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2015-04-20 23:58:42,439 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-20 23:58:42,441 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-20 23:58:42,442 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-20 23:58:42,443 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 00:15:25,140 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 00:15:26,667 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:15:35,273 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-3] - Bound to /0.0.0.0:7070
2015-04-21 00:15:35,274 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-3] - Bound received. EventServer is ready.
2015-04-21 00:15:36,546 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 00:15:36,663 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 00:15:36,673 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 00:15:36,681 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 00:15:36,688 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 00:15:36,697 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 00:15:36,701 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-21 00:15:50,523 ERROR io.prediction.tools.console.App$ [main] - App TextaPP1 does not exist. Aborting.
2015-04-21 00:15:58,989 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-21 00:15:58,991 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp1
2015-04-21 00:15:58,992 INFO  io.prediction.tools.console.App$ [main] -       App ID: 5
2015-04-21 00:15:58,992 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 00:16:01,352 INFO  io.prediction.tools.console.App$ [main] - Aborted.
2015-04-21 00:16:05,417 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-21 00:16:05,419 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp1
2015-04-21 00:16:05,419 INFO  io.prediction.tools.console.App$ [main] -       App ID: 5
2015-04-21 00:16:05,420 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 00:16:06,945 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:16:23,231 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_5...
2015-04-21 00:16:28,630 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 5
2015-04-21 00:16:33,875 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_5 doesn't exist yet. Creating now...
2015-04-21 00:16:39,263 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 5.
2015-04-21 00:16:39,367 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 00:16:45,460 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 00:16:45,531 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 00:16:45,540 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 00:16:45,548 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 00:16:45,554 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 00:16:45,561 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 00:16:45,561 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-21 00:17:52,086 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:17:52,121 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 00:17:52,122 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 00:17:52,124 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 00:17:52,124 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 00:18:12,381 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m/Users/Marco/TextManipulationEngine/src/main/scala/TextManipulationEngine/CountVectorizer.scala:37: value foreach is not a member of java.util.Iterator[opennlp.tools.util.StringList][0m
2015-04-21 00:18:12,382 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m    for (x <- model.iterator)[0m
2015-04-21 00:18:12,382 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m                    ^[0m
2015-04-21 00:18:12,926 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m/Users/Marco/TextManipulationEngine/src/main/scala/TextManipulationEngine/Model.scala:13: `abstract' modifier can be used only for classes; it should be omitted for abstract members[0m
2015-04-21 00:18:12,928 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m  abstract def predict(doc: String): PredictedResult[0m
2015-04-21 00:18:12,928 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m               ^[0m
2015-04-21 00:18:13,174 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0mtwo errors found[0m
2015-04-21 00:18:13,199 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m(compile:[31mcompile[0m) Compilation failed[0m
2015-04-21 00:18:13,203 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0mTotal time: 10 s, completed Apr 21, 2015 12:18:13 AM[0m
2015-04-21 00:18:13,374 ERROR io.prediction.tools.console.Console$ [main] - Return code of previous step is 1. Aborting.
2015-04-21 00:23:42,994 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 00:23:43,054 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 00:23:43,066 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 00:23:43,072 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 00:23:43,081 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 00:23:43,090 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 00:23:43,091 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-21 00:23:57,150 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:23:57,203 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 00:23:57,204 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 00:23:57,205 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 00:23:57,205 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 00:24:15,243 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 00:24:15,244 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 00:24:15,253 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:24:15,253 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:24:15,261 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 00:24:17,012 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:24:17,144 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:24:17,214 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:24:17,236 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 00:24:17,365 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 00:24:21,358 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:24:23,586 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:24:23,732 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 00:24:25,800 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:24:27,505 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 00:24:27,661 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 00:24:27,677 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 00:24:27,678 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 00:24:27,680 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 00:24:27,688 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 00:24:27,688 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 00:24:31,034 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 00:24:31,414 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-186-107.calvisitor.1918.berkeley.edu:60131]
2015-04-21 00:24:33,205 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 00:24:33,206 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@2921199d
2015-04-21 00:24:33,207 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@59fc6d05
2015-04-21 00:24:33,207 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@23ad71bf)
2015-04-21 00:24:33,208 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 00:24:39,594 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 00:24:39,595 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 00:26:08,381 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:26:08,611 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 00:26:08,613 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 00:26:08,615 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 00:26:08,627 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 00:26:42,541 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 00:26:42,542 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 00:26:42,548 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:26:42,548 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:26:42,555 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 00:26:44,185 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:26:44,297 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:26:44,384 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:26:44,396 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 00:26:44,424 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 00:26:48,404 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:26:50,100 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:26:50,224 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 00:26:52,270 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:26:53,283 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 00:26:53,391 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 00:26:53,405 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 00:26:53,405 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 00:26:53,406 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 00:26:53,412 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 00:26:53,412 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 00:26:55,164 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-21 00:26:55,343 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-186-107.calvisitor.1918.berkeley.edu:60199]
2015-04-21 00:26:56,296 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 00:26:56,297 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 00:26:56,297 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 00:26:56,298 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 00:26:56,298 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 00:27:02,651 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 00:27:02,652 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 00:27:24,105 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 00:27:24,106 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 00:27:24,107 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUza32AT9IE4ZnWr8eIL
2015-04-21 00:27:24,122 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 00:27:24,289 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 00:27:24,322 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 00:27:31,586 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUza32AT9IE4ZnWr8eIL --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUza32AT9IE4ZnWr8eIL --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 00:27:35,509 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to TextManipulationEngine.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 00:27:35,516 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 00:27:35,750 ERROR akka.actor.OneForOneStrategy [pio-server-akka.actor.default-dispatcher-3] - Failed to invert: [B@2d5e0a53
com.twitter.bijection.InversionFailure: Failed to invert: [B@2d5e0a53
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:43)
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:42)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure.recoverWith(Try.scala:172)
	at com.twitter.bijection.Inversion$.attempt(Inversion.scala:30)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:55)
	at io.prediction.workflow.CreateServer$.createServerActorWithEngine(CreateServer.scala:197)
	at io.prediction.workflow.MasterActor.createServerActor(CreateServer.scala:364)
	at io.prediction.workflow.MasterActor$$anonfun$receive$2.applyOrElse(CreateServer.scala:287)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at io.prediction.workflow.MasterActor.aroundReceive(CreateServer.scala:250)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
Serialization trace:
TextManipulationEngine$CountVectorizer$$universe (TextManipulationEngine.CountVectorizer)
dataModel (TextManipulationEngine.SupervisedModel)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:43)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.SerDeState.readClassAndObject(SerDeState.java:61)
	at com.twitter.chill.KryoPool.fromBytes(KryoPool.java:94)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.bijection.Inversion$$anonfun$attempt$1.apply(Inversion.scala:30)
	at scala.util.Try$.apply(Try.scala:161)
	... 17 more
Caused by: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171)
	at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:83)
	at java.lang.reflect.Field.set(Field.java:764)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:619)
	... 31 more
2015-04-21 00:31:04,944 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:31:04,991 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 00:31:04,991 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 00:31:04,992 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 00:31:04,993 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 00:31:21,235 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 00:31:21,235 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 00:31:21,244 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:31:21,244 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:31:21,256 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 00:31:23,029 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:31:23,168 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:31:23,254 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:31:23,266 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 00:31:23,301 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 00:31:26,527 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:31:28,244 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:31:28,379 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 00:31:30,287 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:31:31,204 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 00:31:31,290 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 00:31:31,302 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 00:31:31,303 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 00:31:31,304 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 00:31:31,310 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 00:31:31,310 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 00:31:33,037 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-21 00:31:33,280 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-186-107.calvisitor.1918.berkeley.edu:60331]
2015-04-21 00:31:34,693 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 00:31:34,694 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 00:31:34,695 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 00:31:34,695 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 00:31:34,696 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 00:31:46,102 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 00:31:46,103 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 00:33:21,598 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:33:21,704 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 00:33:21,704 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 00:33:21,707 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 00:33:21,709 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 00:33:38,065 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 00:33:38,066 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 00:33:38,073 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:33:38,073 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:33:38,080 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 00:33:39,725 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:33:39,837 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:33:39,938 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:33:39,949 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 00:33:39,971 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 00:33:43,721 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:33:45,439 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:33:45,557 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 00:33:47,602 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:33:48,637 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 00:33:48,745 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 00:33:48,759 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 00:33:48,759 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 00:33:48,761 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 00:33:48,766 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 00:33:48,767 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 00:33:50,565 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 00:33:50,795 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-186-107.calvisitor.1918.berkeley.edu:60397]
2015-04-21 00:33:51,964 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 00:33:51,964 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 00:33:51,965 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 00:33:51,966 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 00:33:51,966 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 00:33:58,379 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 00:33:58,380 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 00:34:19,633 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 00:34:19,633 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 00:34:19,634 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUza5baa9IE4ZnWr8eIN
2015-04-21 00:34:19,648 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 00:34:19,798 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 00:34:19,810 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 00:34:29,005 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUza5baa9IE4ZnWr8eIN --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUza5baa9IE4ZnWr8eIN --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 00:34:32,815 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-4] - Non-empty parameters supplied to TextManipulationEngine.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 00:34:32,830 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-4] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 00:34:33,075 ERROR akka.actor.OneForOneStrategy [pio-server-akka.actor.default-dispatcher-4] - Failed to invert: [B@1c31f8e1
com.twitter.bijection.InversionFailure: Failed to invert: [B@1c31f8e1
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:43)
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:42)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure.recoverWith(Try.scala:172)
	at com.twitter.bijection.Inversion$.attempt(Inversion.scala:30)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:55)
	at io.prediction.workflow.CreateServer$.createServerActorWithEngine(CreateServer.scala:197)
	at io.prediction.workflow.MasterActor.createServerActor(CreateServer.scala:364)
	at io.prediction.workflow.MasterActor$$anonfun$receive$2.applyOrElse(CreateServer.scala:287)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at io.prediction.workflow.MasterActor.aroundReceive(CreateServer.scala:250)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
Serialization trace:
TextManipulationEngine$CountVectorizer$$universe (TextManipulationEngine.CountVectorizer)
dataModel (TextManipulationEngine.SupervisedModel)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:43)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.SerDeState.readClassAndObject(SerDeState.java:61)
	at com.twitter.chill.KryoPool.fromBytes(KryoPool.java:94)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.bijection.Inversion$$anonfun$attempt$1.apply(Inversion.scala:30)
	at scala.util.Try$.apply(Try.scala:161)
	... 17 more
Caused by: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171)
	at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:83)
	at java.lang.reflect.Field.set(Field.java:764)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:619)
	... 31 more
2015-04-21 00:35:55,743 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:35:55,792 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 00:35:55,793 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 00:35:55,794 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 00:35:55,794 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 00:36:12,930 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 00:36:12,931 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 00:36:12,937 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:36:12,937 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:36:12,944 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 00:36:14,697 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:36:14,797 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 00:36:14,890 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 00:36:14,905 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 00:36:14,928 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 00:36:18,147 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 00:36:19,841 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:36:19,953 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 00:36:21,780 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 00:36:22,652 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 00:36:22,737 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 00:36:22,749 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 00:36:22,750 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 00:36:22,751 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 00:36:22,756 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 00:36:22,757 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 00:36:24,454 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-21 00:36:24,630 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-186-107.calvisitor.1918.berkeley.edu:60501]
2015-04-21 00:36:25,612 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 00:36:25,613 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 00:36:25,613 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 00:36:25,614 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 00:36:25,615 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 00:36:32,039 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 00:36:32,040 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 00:38:10,099 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 00:38:10,100 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 00:38:10,100 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUza6BAy9IE4ZnWr8eIO
2015-04-21 00:38:10,113 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 00:38:10,235 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 00:38:10,247 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 00:38:17,744 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUza6BAy9IE4ZnWr8eIO --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUza6BAy9IE4ZnWr8eIO --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 00:38:21,723 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to TextManipulationEngine.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 00:38:21,729 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 00:38:21,976 ERROR akka.actor.OneForOneStrategy [pio-server-akka.actor.default-dispatcher-3] - Failed to invert: [B@6413f9ee
com.twitter.bijection.InversionFailure: Failed to invert: [B@6413f9ee
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:43)
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:42)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure.recoverWith(Try.scala:172)
	at com.twitter.bijection.Inversion$.attempt(Inversion.scala:30)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:55)
	at io.prediction.workflow.CreateServer$.createServerActorWithEngine(CreateServer.scala:197)
	at io.prediction.workflow.MasterActor.createServerActor(CreateServer.scala:364)
	at io.prediction.workflow.MasterActor$$anonfun$receive$2.applyOrElse(CreateServer.scala:287)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at io.prediction.workflow.MasterActor.aroundReceive(CreateServer.scala:250)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
Serialization trace:
TextManipulationEngine$CountVectorizer$$universe (TextManipulationEngine.CountVectorizer)
dataModel (TextManipulationEngine.SupervisedModel)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:43)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.SerDeState.readClassAndObject(SerDeState.java:61)
	at com.twitter.chill.KryoPool.fromBytes(KryoPool.java:94)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.bijection.Inversion$$anonfun$attempt$1.apply(Inversion.scala:30)
	at scala.util.Try$.apply(Try.scala:161)
	... 17 more
Caused by: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171)
	at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:83)
	at java.lang.reflect.Field.set(Field.java:764)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:619)
	... 31 more
2015-04-21 01:14:24,165 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [main-EventThread] - This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2015-04-21 01:39:35,693 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 01:39:37,598 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:39:45,071 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:39:45,172 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 01:39:45,173 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 01:39:45,174 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 01:39:45,176 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 01:39:46,265 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-4] - Bound to /0.0.0.0:7070
2015-04-21 01:39:46,266 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-4] - Bound received. EventServer is ready.
2015-04-21 01:40:02,063 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 01:40:02,064 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 01:40:02,072 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:40:02,072 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:40:02,080 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 01:40:03,735 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:40:03,849 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:40:03,935 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:40:03,948 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 01:40:04,092 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 01:40:07,564 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:40:09,251 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:40:09,347 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 01:40:11,117 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:40:11,920 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 01:40:12,000 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 01:40:12,013 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 01:40:12,013 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 01:40:12,015 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 01:40:12,028 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 01:40:12,029 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 01:40:13,735 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-4] - Starting remoting
2015-04-21 01:40:13,909 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-4] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:60977]
2015-04-21 01:40:14,879 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 01:40:14,880 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 01:40:14,881 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 01:40:14,882 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 01:40:14,882 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 01:40:20,382 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [main] - ZooKeeper exists failed after 1 attempts
2015-04-21 01:40:20,384 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [main] - hconnection-0x776015fc, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:199)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:479)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:83)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:852)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:657)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:409)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:388)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:269)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:2338)
	at io.prediction.data.storage.hbase.StorageClient.<init>(StorageClient.scala:50)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at io.prediction.data.storage.Storage$.getClient(Storage.scala:149)
	at io.prediction.data.storage.Storage$.io$prediction$data$storage$Storage$$updateS2CM(Storage.scala:73)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at scala.collection.mutable.MapLike$class.getOrElseUpdate(MapLike.scala:189)
	at scala.collection.mutable.AbstractMap.getOrElseUpdate(Map.scala:91)
	at io.prediction.data.storage.Storage$.sourcesToClientMeta(Storage.scala:88)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:222)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:173)
	at io.prediction.data.storage.Storage$.getPEvents(Storage.scala:280)
	at TextManipulationEngine.DataSource.readEventData(DataSource.scala:24)
	at TextManipulationEngine.DataSource.readTraining(DataSource.scala:43)
	at TextManipulationEngine.DataSource.readTraining(DataSource.scala:15)
	at io.prediction.controller.PDataSource.readTrainingBase(DataSource.scala:41)
	at io.prediction.controller.Engine$.train(Engine.scala:518)
	at io.prediction.controller.Engine.train(Engine.scala:147)
	at io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:61)
	at io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:258)
	at io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-04-21 01:40:20,387 WARN  org.apache.hadoop.hbase.client.ZooKeeperRegistry [main] - Can't retrieve clusterId from Zookeeper
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:199)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:479)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:83)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:852)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:657)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:409)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:388)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:269)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:2338)
	at io.prediction.data.storage.hbase.StorageClient.<init>(StorageClient.scala:50)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at io.prediction.data.storage.Storage$.getClient(Storage.scala:149)
	at io.prediction.data.storage.Storage$.io$prediction$data$storage$Storage$$updateS2CM(Storage.scala:73)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at scala.collection.mutable.MapLike$class.getOrElseUpdate(MapLike.scala:189)
	at scala.collection.mutable.AbstractMap.getOrElseUpdate(Map.scala:91)
	at io.prediction.data.storage.Storage$.sourcesToClientMeta(Storage.scala:88)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:222)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:173)
	at io.prediction.data.storage.Storage$.getPEvents(Storage.scala:280)
	at TextManipulationEngine.DataSource.readEventData(DataSource.scala:24)
	at TextManipulationEngine.DataSource.readTraining(DataSource.scala:43)
	at TextManipulationEngine.DataSource.readTraining(DataSource.scala:15)
	at io.prediction.controller.PDataSource.readTrainingBase(DataSource.scala:41)
	at io.prediction.controller.Engine$.train(Engine.scala:518)
	at io.prediction.controller.Engine.train(Engine.scala:147)
	at io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:61)
	at io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:258)
	at io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-04-21 01:40:21,589 ERROR io.prediction.data.storage.hbase.StorageClient [main] - Cannot connect to ZooKeeper (ZooKeeper ensemble: localhost). Please make sure that the configuration is pointing at the correct ZooKeeper ensemble. By default, HBase manages its own ZooKeeper, so if you have not configured HBase to use an external ZooKeeper, that means your HBase is not started or configured properly.
2015-04-21 01:40:21,590 ERROR io.prediction.data.storage.Storage$ [main] - Error initializing storage client for source HBASE
2015-04-21 01:40:21,591 ERROR io.prediction.data.storage.Storage$ [main] - Can't connect to ZooKeeper
2015-04-21 01:40:21,591 ERROR io.prediction.controller.Engine$ [main] - Error occured reading from data source. (Reason: Data source HBASE was not properly initialized.) Please see the log for debugging details.
io.prediction.data.storage.StorageClientException: Data source HBASE was not properly initialized.
	at io.prediction.data.storage.Storage$$anonfun$9.apply(Storage.scala:182)
	at io.prediction.data.storage.Storage$$anonfun$9.apply(Storage.scala:182)
	at scala.Option.getOrElse(Option.scala:120)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:222)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:173)
	at io.prediction.data.storage.Storage$.getPEvents(Storage.scala:280)
	at TextManipulationEngine.DataSource.readEventData(DataSource.scala:24)
	at TextManipulationEngine.DataSource.readTraining(DataSource.scala:43)
	at TextManipulationEngine.DataSource.readTraining(DataSource.scala:15)
	at io.prediction.controller.PDataSource.readTrainingBase(DataSource.scala:41)
	at io.prediction.controller.Engine$.train(Engine.scala:518)
	at io.prediction.controller.Engine.train(Engine.scala:147)
	at io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:61)
	at io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:258)
	at io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-04-21 01:45:39,111 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:45:39,158 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 01:45:39,158 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 01:45:39,159 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 01:45:39,159 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 01:45:45,755 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 01:45:45,756 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 01:45:45,763 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:45:45,763 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:45:45,772 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 01:45:47,402 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:45:47,492 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:45:47,572 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:45:47,584 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 01:45:47,620 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 01:45:51,236 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:45:52,896 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:45:53,009 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 01:45:54,731 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:45:55,564 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 01:45:55,641 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 01:45:55,652 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 01:45:55,652 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 01:45:55,653 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 01:45:55,658 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 01:45:55,658 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 01:45:57,299 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 01:45:57,483 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:61459]
2015-04-21 01:45:58,508 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 01:45:58,508 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 01:45:58,509 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 01:45:58,510 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 01:45:58,510 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 01:46:04,920 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 01:46:04,921 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 01:48:16,201 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:48:16,441 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 01:48:16,442 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 01:48:16,445 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 01:48:16,445 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 01:48:34,122 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 01:48:34,122 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 01:48:34,132 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:48:34,133 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:48:34,148 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 01:48:35,786 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:48:35,890 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:48:35,980 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:48:35,993 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 01:48:36,022 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 01:48:40,747 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:48:42,387 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:48:42,504 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 01:48:44,264 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:48:45,094 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 01:48:45,177 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 01:48:45,187 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 01:48:45,188 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 01:48:45,189 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 01:48:45,193 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 01:48:45,194 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 01:48:46,822 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 01:48:47,012 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:61524]
2015-04-21 01:48:47,990 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 01:48:47,990 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 01:48:47,991 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 01:48:47,991 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 01:48:47,992 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 01:48:49,162 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 01:48:49,164 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 01:48:54,375 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 01:49:39,342 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.HashMap.newNode(HashMap.java:1734)
	at java.util.HashMap.putVal(HashMap.java:630)
	at java.util.HashMap.put(HashMap.java:611)
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:133)
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:166)
	at TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$hashData(CountVectorizer.scala:35)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-21 01:49:39,350 ERROR org.apache.spark.util.SparkUncaughtExceptionHandler [Executor task launch worker-0] - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.HashMap.newNode(HashMap.java:1734)
	at java.util.HashMap.putVal(HashMap.java:630)
	at java.util.HashMap.put(HashMap.java:611)
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:133)
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:166)
	at TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$hashData(CountVectorizer.scala:35)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-21 01:49:39,355 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.HashMap.newNode(HashMap.java:1734)
	at java.util.HashMap.putVal(HashMap.java:630)
	at java.util.HashMap.put(HashMap.java:611)
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:133)
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:166)
	at TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$hashData(CountVectorizer.scala:35)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-21 01:49:39,357 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-21 01:50:38,550 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:50:41,620 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:50:41,826 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 01:50:44,462 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:50:45,807 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 01:50:45,948 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 01:50:45,966 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 01:50:45,967 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 01:50:45,969 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 01:50:45,978 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 01:50:45,980 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 01:50:48,664 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 01:50:48,995 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:61588]
2015-04-21 01:50:50,993 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 01:50:50,996 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@2921199d
2015-04-21 01:50:50,997 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@59fc6d05
2015-04-21 01:50:50,998 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@23ad71bf)
2015-04-21 01:50:51,000 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 01:51:07,854 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 01:51:07,855 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 01:51:08,019 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 01:52:09,754 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:160)
	at TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$hashData(CountVectorizer.scala:35)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-21 01:52:09,773 ERROR org.apache.spark.util.SparkUncaughtExceptionHandler [Executor task launch worker-0] - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:160)
	at TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$hashData(CountVectorizer.scala:35)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-21 01:52:09,776 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:160)
	at TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$hashData(CountVectorizer.scala:35)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at TextManipulationEngine.CountVectorizer$$anonfun$1.apply(CountVectorizer.scala:48)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-21 01:52:09,779 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-21 01:56:00,364 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:56:00,417 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 01:56:00,417 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 01:56:00,418 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 01:56:00,419 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 01:56:14,557 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 01:56:14,558 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 01:56:14,566 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:56:14,566 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:56:14,574 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 01:56:16,573 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:56:16,688 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 01:56:16,773 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 01:56:16,792 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 01:56:16,833 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 01:56:20,039 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 01:56:21,689 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:56:21,819 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 01:56:23,800 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 01:56:24,789 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 01:56:24,901 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 01:56:24,915 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 01:56:24,916 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 01:56:24,918 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 01:56:24,924 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 01:56:24,924 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 01:56:26,681 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 01:56:26,910 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:61722]
2015-04-21 01:56:28,363 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 01:56:28,364 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@43f03c23
2015-04-21 01:56:28,365 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@3d40a3b4
2015-04-21 01:56:28,365 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@78307a56)
2015-04-21 01:56:28,365 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 01:56:29,611 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 01:56:29,612 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 01:56:29,733 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 01:57:04,269 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 01:57:04,270 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 01:57:04,271 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUzbMVZylg-pgU3hEQGe
2015-04-21 01:57:04,283 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 01:57:04,438 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 01:57:04,458 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 01:57:12,312 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUzbMVZylg-pgU3hEQGe --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUzbMVZylg-pgU3hEQGe --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 01:57:15,948 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to TextManipulationEngine.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 01:57:15,963 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 01:57:16,194 ERROR akka.actor.OneForOneStrategy [pio-server-akka.actor.default-dispatcher-3] - Failed to invert: [B@1f52cf03
com.twitter.bijection.InversionFailure: Failed to invert: [B@1f52cf03
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:43)
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:42)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure.recoverWith(Try.scala:172)
	at com.twitter.bijection.Inversion$.attempt(Inversion.scala:30)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:55)
	at io.prediction.workflow.CreateServer$.createServerActorWithEngine(CreateServer.scala:197)
	at io.prediction.workflow.MasterActor.createServerActor(CreateServer.scala:364)
	at io.prediction.workflow.MasterActor$$anonfun$receive$2.applyOrElse(CreateServer.scala:287)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at io.prediction.workflow.MasterActor.aroundReceive(CreateServer.scala:250)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
Serialization trace:
TextManipulationEngine$CountVectorizer$$universe (TextManipulationEngine.CountVectorizer)
dataModel (TextManipulationEngine.SupervisedModel)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:43)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.SerDeState.readClassAndObject(SerDeState.java:61)
	at com.twitter.chill.KryoPool.fromBytes(KryoPool.java:94)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.bijection.Inversion$$anonfun$attempt$1.apply(Inversion.scala:30)
	at scala.util.Try$.apply(Try.scala:161)
	... 17 more
Caused by: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171)
	at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:83)
	at java.lang.reflect.Field.set(Field.java:764)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:619)
	... 31 more
2015-04-21 02:11:17,253 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 02:11:18,546 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:11:26,163 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-2] - Bound to /0.0.0.0:7070
2015-04-21 02:11:26,164 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-2] - Bound received. EventServer is ready.
2015-04-21 02:11:34,287 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 02:11:34,334 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 02:11:34,335 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 02:11:34,337 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 02:11:34,337 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 02:11:50,039 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 02:11:50,039 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 02:11:50,045 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 02:11:50,046 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 02:11:50,052 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 02:11:51,686 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:11:51,792 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 02:11:51,870 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 02:11:51,898 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 02:11:51,957 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 02:11:56,149 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 02:11:57,794 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:11:57,924 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 02:11:59,696 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:12:00,575 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 02:12:00,645 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 02:12:00,660 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 02:12:00,660 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 02:12:00,661 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 02:12:00,666 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 02:12:00,667 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 02:12:02,413 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 02:12:02,598 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:62045]
2015-04-21 02:12:03,580 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 02:12:03,580 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@2921199d
2015-04-21 02:12:03,581 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@59fc6d05
2015-04-21 02:12:03,581 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@23ad71bf)
2015-04-21 02:12:03,582 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 02:12:09,947 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 02:12:09,948 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 02:12:10,089 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 02:12:45,664 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 02:12:45,665 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 02:12:45,666 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUzbP53D2BYFOcR65-LN
2015-04-21 02:12:45,683 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 02:12:45,802 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 02:12:45,821 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 02:12:54,357 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUzbP53D2BYFOcR65-LN --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUzbP53D2BYFOcR65-LN --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 02:12:58,156 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-4] - Non-empty parameters supplied to TextManipulationEngine.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 02:12:58,162 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-4] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 02:12:58,444 ERROR akka.actor.OneForOneStrategy [pio-server-akka.actor.default-dispatcher-4] - Failed to invert: [B@7134b8f4
com.twitter.bijection.InversionFailure: Failed to invert: [B@7134b8f4
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:43)
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:42)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure.recoverWith(Try.scala:172)
	at com.twitter.bijection.Inversion$.attempt(Inversion.scala:30)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:55)
	at io.prediction.workflow.CreateServer$.createServerActorWithEngine(CreateServer.scala:197)
	at io.prediction.workflow.MasterActor.createServerActor(CreateServer.scala:364)
	at io.prediction.workflow.MasterActor$$anonfun$receive$2.applyOrElse(CreateServer.scala:287)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at io.prediction.workflow.MasterActor.aroundReceive(CreateServer.scala:250)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.universe to scala.collection.mutable.HashSet
Serialization trace:
universe (TextManipulationEngine.CountVectorizer)
dataModel (TextManipulationEngine.SupervisedModel)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:43)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.SerDeState.readClassAndObject(SerDeState.java:61)
	at com.twitter.chill.KryoPool.fromBytes(KryoPool.java:94)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.bijection.Inversion$$anonfun$attempt$1.apply(Inversion.scala:30)
	at scala.util.Try$.apply(Try.scala:161)
	... 17 more
Caused by: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.universe to scala.collection.mutable.HashSet
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171)
	at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:83)
	at java.lang.reflect.Field.set(Field.java:764)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:619)
	... 31 more
2015-04-21 02:15:42,870 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 02:15:42,921 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 02:15:42,921 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 02:15:42,922 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 02:15:42,923 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 02:15:55,643 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 02:15:55,643 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 02:15:55,652 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 02:15:55,653 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 02:15:55,662 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 02:15:57,205 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:15:57,305 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 02:15:57,376 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 02:15:57,390 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 02:15:57,412 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 02:16:00,750 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 02:16:02,487 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:16:02,591 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 02:16:04,393 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:16:05,229 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 02:16:05,301 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 02:16:05,311 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 02:16:05,311 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 02:16:05,312 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 02:16:05,317 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 02:16:05,318 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 02:16:06,931 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 02:16:07,109 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:62152]
2015-04-21 02:16:08,089 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 02:16:08,090 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@23ad71bf
2015-04-21 02:16:08,090 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@b791a81
2015-04-21 02:16:08,091 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@71e7adbb)
2015-04-21 02:16:08,091 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 02:16:24,564 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 02:16:24,565 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 02:16:24,701 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 02:18:18,141 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 02:18:18,143 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 02:18:18,149 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUzbQ1lH2BYFOcR65-LO
2015-04-21 02:18:18,283 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 02:18:18,966 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 02:18:19,050 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 02:18:38,947 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUzbQ1lH2BYFOcR65-LO --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUzbQ1lH2BYFOcR65-LO --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 02:18:42,766 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-3] - Non-empty parameters supplied to TextManipulationEngine.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 02:18:42,774 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-3] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 02:18:42,990 ERROR akka.actor.OneForOneStrategy [pio-server-akka.actor.default-dispatcher-4] - Failed to invert: [B@1003d4b8
com.twitter.bijection.InversionFailure: Failed to invert: [B@1003d4b8
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:43)
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:42)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure.recoverWith(Try.scala:172)
	at com.twitter.bijection.Inversion$.attempt(Inversion.scala:30)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:55)
	at io.prediction.workflow.CreateServer$.createServerActorWithEngine(CreateServer.scala:197)
	at io.prediction.workflow.MasterActor.createServerActor(CreateServer.scala:364)
	at io.prediction.workflow.MasterActor$$anonfun$receive$2.applyOrElse(CreateServer.scala:287)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at io.prediction.workflow.MasterActor.aroundReceive(CreateServer.scala:250)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
Serialization trace:
TextManipulationEngine$CountVectorizer$$universe (TextManipulationEngine.CountVectorizer)
dataModel (TextManipulationEngine.SupervisedModel)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:43)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.SerDeState.readClassAndObject(SerDeState.java:61)
	at com.twitter.chill.KryoPool.fromBytes(KryoPool.java:94)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.bijection.Inversion$$anonfun$attempt$1.apply(Inversion.scala:30)
	at scala.util.Try$.apply(Try.scala:161)
	... 17 more
Caused by: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.CountVectorizer.TextManipulationEngine$CountVectorizer$$universe to scala.collection.mutable.HashSet
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171)
	at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:83)
	at java.lang.reflect.Field.set(Field.java:764)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:619)
	... 31 more
2015-04-21 02:26:50,892 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 02:26:50,943 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 02:26:50,943 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 02:26:50,945 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 02:26:50,945 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 02:27:05,616 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 02:27:05,617 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 02:27:05,623 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 02:27:05,623 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 02:27:05,629 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 02:27:07,218 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:27:07,317 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 02:27:07,387 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 02:27:07,402 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 02:27:07,425 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 02:27:12,697 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 02:27:14,344 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:27:14,459 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 02:27:16,201 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 02:27:17,005 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 02:27:17,099 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 02:27:17,113 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 02:27:17,114 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 02:27:17,115 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-21 02:27:17,121 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 02:27:17,122 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 02:27:18,747 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 02:27:18,908 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:62295]
2015-04-21 02:27:19,844 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 02:27:19,845 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@2921199d
2015-04-21 02:27:19,845 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@59fc6d05
2015-04-21 02:27:19,846 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@23ad71bf)
2015-04-21 02:27:19,846 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 02:27:26,165 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 02:27:26,166 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 02:27:31,384 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 02:28:05,494 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 02:28:05,495 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 02:28:05,495 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUzbTZmh2BYFOcR65-LP
2015-04-21 02:28:05,510 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 02:28:05,624 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 02:28:05,636 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 02:28:14,217 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUzbTZmh2BYFOcR65-LP --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUzbTZmh2BYFOcR65-LP --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 02:28:17,895 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-3] - Non-empty parameters supplied to TextManipulationEngine.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 02:28:17,902 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-3] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 02:28:18,116 ERROR akka.actor.OneForOneStrategy [pio-server-akka.actor.default-dispatcher-3] - Failed to invert: [B@1aa38564
com.twitter.bijection.InversionFailure: Failed to invert: [B@1aa38564
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:43)
	at com.twitter.bijection.InversionFailure$$anonfun$partialFailure$1.applyOrElse(InversionFailure.scala:42)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at scala.util.Failure.recoverWith(Try.scala:172)
	at com.twitter.bijection.Inversion$.attempt(Inversion.scala:30)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance.invert(KryoInjection.scala:55)
	at io.prediction.workflow.CreateServer$.createServerActorWithEngine(CreateServer.scala:197)
	at io.prediction.workflow.MasterActor.createServerActor(CreateServer.scala:364)
	at io.prediction.workflow.MasterActor$$anonfun$receive$2.applyOrElse(CreateServer.scala:287)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at io.prediction.workflow.MasterActor.aroundReceive(CreateServer.scala:250)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.Universe.universe to scala.collection.mutable.HashSet
Serialization trace:
universe (TextManipulationEngine.Universe)
TextManipulationEngine$CountVectorizer$$universe (TextManipulationEngine.CountVectorizer)
dataModel (TextManipulationEngine.SupervisedModel)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:43)
	at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
	at com.twitter.chill.SerDeState.readClassAndObject(SerDeState.java:61)
	at com.twitter.chill.KryoPool.fromBytes(KryoPool.java:94)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.chill.KryoInjectionInstance$$anonfun$invert$2.apply(KryoInjection.scala:65)
	at com.twitter.bijection.Inversion$$anonfun$attempt$1.apply(Inversion.scala:30)
	at scala.util.Try$.apply(Try.scala:161)
	... 17 more
Caused by: java.lang.IllegalArgumentException: Can not set final scala.collection.mutable.LinkedHashSet field TextManipulationEngine.Universe.universe to scala.collection.mutable.HashSet
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)
	at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:171)
	at sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:83)
	at java.lang.reflect.Field.set(Field.java:764)
	at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:619)
	... 34 more
2015-04-21 10:51:04,981 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [main-EventThread] - This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2015-04-21 17:47:41,108 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 17:47:42,887 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 17:47:43,611 ERROR io.prediction.data.storage.hbase.StorageClient [main] - HBase master is not running (ZooKeeper ensemble: localhost). Please make sure that HBase is running properly, and that the configuration is pointing at the correct ZooKeeper ensemble.
2015-04-21 17:47:43,612 ERROR io.prediction.data.storage.Storage$ [main] - Error initializing storage client for source HBASE
2015-04-21 17:47:43,613 ERROR io.prediction.data.storage.Storage$ [main] - com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.ipc.ServerNotRunningYetException): org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.56/192.168.1.56:63191 is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-21 17:48:05,182 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 17:48:05,299 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 17:48:05,317 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 17:48:05,332 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 17:48:05,362 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 17:48:05,386 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 17:48:05,388 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-21 17:48:17,388 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-21 17:48:17,390 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp1
2015-04-21 17:48:17,390 INFO  io.prediction.tools.console.App$ [main] -       App ID: 5
2015-04-21 17:48:17,391 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 17:48:20,191 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 17:48:26,288 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_5...
2015-04-21 17:48:37,022 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 5
2015-04-21 17:48:47,336 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_5 doesn't exist yet. Creating now...
2015-04-21 17:48:47,621 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 5.
2015-04-21 17:48:47,724 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 17:50:50,224 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 17:50:51,476 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 17:50:52,226 ERROR io.prediction.data.storage.hbase.StorageClient [main] - HBase master is not running (ZooKeeper ensemble: localhost). Please make sure that HBase is running properly, and that the configuration is pointing at the correct ZooKeeper ensemble.
2015-04-21 17:50:52,227 ERROR io.prediction.data.storage.Storage$ [main] - Error initializing storage client for source HBASE
2015-04-21 17:50:52,227 ERROR io.prediction.data.storage.Storage$ [main] - com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.ipc.ServerNotRunningYetException): org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.56/192.168.1.56:63299 is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-21 17:53:46,923 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 17:53:47,056 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 17:53:47,070 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 17:53:47,083 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 17:53:47,100 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 17:53:47,127 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 17:53:47,129 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-21 17:55:40,334 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 17:55:41,719 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 17:55:46,807 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 17:55:46,908 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 17:55:46,924 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 17:55:46,986 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 17:55:47,020 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 17:55:47,089 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 17:55:47,090 INFO  io.prediction.tools.console.App$ [main] - Finished listing 5 app(s).
2015-04-21 17:55:54,562 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-4] - Bound to /0.0.0.0:7070
2015-04-21 17:55:54,563 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-4] - Bound received. EventServer is ready.
2015-04-21 18:01:56,100 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:01:56,149 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 18:01:56,149 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 18:01:56,150 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 18:01:56,151 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 18:02:12,178 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 18:02:12,179 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 18:02:12,185 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:02:12,185 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:02:12,191 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 18:02:13,842 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:02:13,954 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:02:14,045 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:02:14,069 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 18:02:14,165 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 18:02:18,632 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:02:20,323 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:02:20,450 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 18:02:22,458 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:02:23,453 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 18:02:23,561 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:02:23,576 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 18:02:23,576 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 18:02:23,577 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:02:23,579 INFO  io.prediction.controller.Engine [main] - Preparator params: (,PreparatorParams(1,2))
2015-04-21 18:02:23,585 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 18:02:23,586 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 18:02:25,342 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 18:02:25,590 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:63478]
2015-04-21 18:02:27,209 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 18:02:27,210 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@47b269c4
2015-04-21 18:02:27,211 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@7c40ffef
2015-04-21 18:02:27,211 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@1e3df614)
2015-04-21 18:02:27,212 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 18:02:38,615 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 18:02:43,820 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 18:03:36,257 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:166)
	at TextManipulationEngine.DataModel.TextManipulationEngine$DataModel$$hashDoc(DataModel.scala:36)
	at TextManipulationEngine.DataModel$$anonfun$1.apply(DataModel.scala:58)
	at TextManipulationEngine.DataModel$$anonfun$1.apply(DataModel.scala:58)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-21 18:03:36,321 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:166)
	at TextManipulationEngine.DataModel.TextManipulationEngine$DataModel$$hashDoc(DataModel.scala:36)
	at TextManipulationEngine.DataModel$$anonfun$1.apply(DataModel.scala:58)
	at TextManipulationEngine.DataModel$$anonfun$1.apply(DataModel.scala:58)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-21 18:03:36,328 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-21 18:03:36,453 ERROR org.apache.spark.util.SparkUncaughtExceptionHandler [Executor task launch worker-0] - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at opennlp.tools.ngram.NGramModel.add(NGramModel.java:166)
	at TextManipulationEngine.DataModel.TextManipulationEngine$DataModel$$hashDoc(DataModel.scala:36)
	at TextManipulationEngine.DataModel$$anonfun$1.apply(DataModel.scala:58)
	at TextManipulationEngine.DataModel$$anonfun$1.apply(DataModel.scala:58)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-21 18:16:56,532 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:16:56,578 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 18:16:56,578 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 18:16:56,580 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 18:16:56,580 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 18:17:08,659 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 18:17:08,659 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 18:17:08,666 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:17:08,667 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:17:08,674 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 18:17:10,266 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:17:10,366 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:17:10,444 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:17:10,456 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 18:17:10,480 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 18:17:17,983 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:17:19,649 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:17:19,768 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 18:17:21,553 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:17:22,371 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 18:17:22,453 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:17:22,463 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(5))
2015-04-21 18:17:22,464 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 18:17:22,465 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:17:22,467 INFO  io.prediction.controller.Engine [main] - Preparator params: (,PreparatorParams(1,2))
2015-04-21 18:17:22,472 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 18:17:22,474 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 18:17:24,126 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-21 18:17:24,316 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:63712]
2015-04-21 18:17:25,346 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 18:17:25,346 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@59fc6d05
2015-04-21 18:17:25,347 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@23ad71bf
2015-04-21 18:17:25,348 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@b791a81)
2015-04-21 18:17:25,348 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 18:17:36,791 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 18:17:36,937 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 18:17:48,957 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 18:17:58,182 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 18:17:58,182 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 18:17:58,183 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUzes27KZeO1jiHMEW-_
2015-04-21 18:17:58,198 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 18:17:58,350 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 18:17:58,371 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 18:18:09,360 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUzes27KZeO1jiHMEW-_ --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUzes27KZeO1jiHMEW-_ --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 18:18:13,148 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-3] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 18:18:13,563 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Starting remoting
2015-04-21 18:18:13,746 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:63754]
2015-04-21 18:18:15,069 WARN  org.apache.hadoop.util.NativeCodeLoader [pio-server-akka.actor.default-dispatcher-3] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:18:15,984 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-3] - Using persisted model
2015-04-21 18:18:15,985 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-3] - Loaded model TextManipulationEngine.SupervisedModel for algorithm TextManipulationEngine.SupervisedAlgorithm
2015-04-21 18:18:15,998 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-4] - Undeploying any existing engine instance at http://localhost:8000
2015-04-21 18:18:16,032 WARN  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-4] - Nothing at http://localhost:8000
2015-04-21 18:18:16,799 INFO  spray.can.server.HttpListener [pio-server-akka.actor.default-dispatcher-5] - Bound to localhost/127.0.0.1:8000
2015-04-21 18:18:16,800 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-7] - Bind successful. Ready to serve.
2015-04-21 18:33:07,934 WARN  spray.can.server.HttpServerConnection [pio-server-akka.actor.default-dispatcher-17] - Illegal request, responding with status '413 Request Entity Too Large': Request Content-Length 14218200 exceeds the configured limit of 8388608
2015-04-21 18:47:25,593 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 18:47:26,841 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:47:29,301 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-3] - Bound to /0.0.0.0:7070
2015-04-21 18:47:29,303 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-3] - Bound received. EventServer is ready.
2015-04-21 18:48:21,361 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:48:22,340 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_6 doesn't exist yet. Creating now...
2015-04-21 18:48:22,667 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 6.
2015-04-21 18:48:22,690 INFO  io.prediction.tools.console.App$ [main] - Created new app:
2015-04-21 18:48:22,690 INFO  io.prediction.tools.console.App$ [main] -       Name: TextApp
2015-04-21 18:48:22,690 INFO  io.prediction.tools.console.App$ [main] -         ID: 6
2015-04-21 18:48:22,691 INFO  io.prediction.tools.console.App$ [main] - Access Key: 4MM9gXNr3LkMCSCfCoZcVzaWPJi1Gbpn2Hm1PiIvsSRVONiaSqhSRemUSnkaUZng
2015-04-21 18:50:38,465 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:50:38,512 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 18:50:38,512 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 18:50:38,513 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 18:50:38,513 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 18:50:53,841 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 18:50:53,842 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 18:50:53,852 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:50:53,852 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:50:53,863 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 18:50:55,695 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:50:55,781 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:50:55,871 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:50:55,888 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 18:50:55,926 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 18:50:59,787 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:51:01,451 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:51:01,565 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 18:51:03,364 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:51:04,218 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 18:51:04,301 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:51:04,312 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(6))
2015-04-21 18:51:04,312 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 18:51:04,313 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:51:04,315 INFO  io.prediction.controller.Engine [main] - Preparator params: (,PreparatorParams(1,2))
2015-04-21 18:51:04,320 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 18:51:04,321 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 18:51:06,031 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 18:51:06,220 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:63948]
2015-04-21 18:51:07,219 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 18:51:07,220 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@47b269c4
2015-04-21 18:51:07,220 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@7c40ffef
2015-04-21 18:51:07,221 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@1e3df614)
2015-04-21 18:51:07,221 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 18:51:13,507 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 18:51:18,736 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 18:51:19,427 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 18:53:20,413 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:53:20,656 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 18:53:20,660 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 18:53:20,663 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 18:53:20,668 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 18:54:00,559 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 18:54:00,559 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 18:54:00,565 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:54:00,565 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:54:00,572 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 18:54:02,334 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:54:02,430 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:54:02,500 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:54:02,514 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 18:54:02,538 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 18:55:12,880 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:55:12,950 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 18:55:12,954 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 18:55:12,956 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 18:55:12,959 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 18:55:25,790 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 18:55:25,791 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 18:55:25,798 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:55:25,798 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:55:25,805 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 18:55:27,466 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:55:27,573 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 18:55:27,651 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 18:55:27,664 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 18:55:27,690 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 18:55:37,015 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 18:55:38,670 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:55:38,787 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 18:55:40,587 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 18:55:41,407 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 18:55:41,479 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:55:41,492 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(6))
2015-04-21 18:55:41,492 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 18:55:41,493 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 18:55:41,495 INFO  io.prediction.controller.Engine [main] - Preparator params: (,PreparatorParams(1,2))
2015-04-21 18:55:41,499 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 18:55:41,501 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 18:55:43,145 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-21 18:55:43,316 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:64040]
2015-04-21 18:55:44,358 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 18:55:44,359 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@b791a81
2015-04-21 18:55:44,359 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@71e7adbb
2015-04-21 18:55:44,359 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@286855ea)
2015-04-21 18:55:44,360 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 18:55:50,666 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 18:55:50,809 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 18:55:51,508 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 19:04:02,809 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 19:04:02,935 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 19:04:02,965 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 19:04:03,013 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 19:04:03,043 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 19:04:03,059 INFO  io.prediction.tools.console.App$ [main] -              TextApp |    6 | 4MM9gXNr3LkMCSCfCoZcVzaWPJi1Gbpn2Hm1PiIvsSRVONiaSqhSRemUSnkaUZng | (all)
2015-04-21 19:04:03,070 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 19:04:03,086 INFO  io.prediction.tools.console.App$ [main] - Finished listing 6 app(s).
2015-04-21 19:04:13,968 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 19:04:14,014 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 19:04:14,017 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 19:04:14,018 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 19:04:14,019 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 19:04:25,753 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 19:04:25,754 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 19:04:25,762 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 19:04:25,763 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 19:04:25,771 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 19:04:28,228 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 19:04:28,400 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 19:04:28,549 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 19:04:28,605 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 19:04:28,654 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 19:04:35,965 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 19:04:38,777 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 19:04:38,953 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 19:04:41,667 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 19:04:42,975 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 19:04:43,100 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 19:04:43,118 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(6))
2015-04-21 19:04:43,118 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 19:04:43,119 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 19:04:43,122 INFO  io.prediction.controller.Engine [main] - Preparator params: (,PreparatorParams(1,2))
2015-04-21 19:04:43,129 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 19:04:43,132 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 19:04:46,028 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-21 19:04:46,329 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.56:64198]
2015-04-21 19:04:48,468 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 19:04:48,469 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@47b269c4
2015-04-21 19:04:48,470 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@7c40ffef
2015-04-21 19:04:48,471 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@1e3df614)
2015-04-21 19:04:48,474 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 19:04:55,154 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 19:04:55,297 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /192.168.1.56 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '56.1.168.192.in-addr.arpa'
2015-04-21 19:04:56,295 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 20:20:25,637 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [main-EventThread] - This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2015-04-21 22:08:15,459 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 22:08:16,646 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:08:24,742 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 22:08:24,843 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 22:08:24,862 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 22:08:24,878 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 22:08:24,899 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 22:08:24,914 INFO  io.prediction.tools.console.App$ [main] -              TextApp |    6 | 4MM9gXNr3LkMCSCfCoZcVzaWPJi1Gbpn2Hm1PiIvsSRVONiaSqhSRemUSnkaUZng | (all)
2015-04-21 22:08:24,933 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 22:08:24,934 INFO  io.prediction.tools.console.App$ [main] - Finished listing 6 app(s).
2015-04-21 22:08:29,082 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-2] - Bound to /0.0.0.0:7070
2015-04-21 22:08:29,083 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-2] - Bound received. EventServer is ready.
2015-04-21 22:09:10,649 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:09:10,649 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:09:13,478 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:09:13,479 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:09:29,648 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:09:29,648 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:09:31,786 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:09:31,787 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:09:47,902 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:09:47,902 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:09:50,727 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:09:50,727 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:10:05,579 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:10:05,580 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:10:09,977 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:10:09,977 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:10:23,732 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:10:23,732 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:10:28,516 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:10:28,516 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:10:41,611 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:10:41,611 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:10:48,020 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:10:48,020 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:10:59,226 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:10:59,227 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:11:05,570 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:11:05,571 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:11:19,280 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:11:19,280 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:11:25,950 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:11:25,950 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:11:40,768 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:11:40,769 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:11:46,330 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:11:46,330 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:11:59,751 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-3] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:11:59,752 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-3] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:12:05,259 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [EventServerSystem-akka.actor.default-dispatcher-7] - ZooKeeper getData failed after 4 attempts
2015-04-21 22:12:05,259 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [EventServerSystem-akka.actor.default-dispatcher-7] - hconnection-0x60c16548-0x14cdf86a6630006, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:337)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:683)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.blockUntilAvailable(ZKUtil.java:1835)
	at org.apache.hadoop.hbase.zookeeper.MetaRegionTracker.blockUntilAvailable(MetaRegionTracker.java:183)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:58)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1196)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:12:36,963 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 22:12:38,574 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:12:41,328 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-4] - Bound to /0.0.0.0:7070
2015-04-21 22:12:41,329 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-4] - Bound received. EventServer is ready.
2015-04-21 22:13:15,736 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 22:13:15,897 INFO  io.prediction.tools.console.App$ [main] -      FinalDeployTest |    4 | 3p42NlUE6uqwOX39vGSd0djm6QvdgiriZ1lmQnzPinPjHiYnaimxr5KP89s9ue53 | (all)
2015-04-21 22:13:15,910 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    1 | ddu1ynBz4ONm9bxqPE73RvagJeQNNauZkHU5CsH3h5CFJU6rKM5Kc0uiezP7ZCLw | (all)
2015-04-21 22:13:15,918 INFO  io.prediction.tools.console.App$ [main] -               MyApp2 |    2 | Ou8SV0FJoP84LfSyXy3cBLV2TgWSHV9q2BiNgQLy4Zuji0RiJ6nfNKMp8kUGdC9O | (all)
2015-04-21 22:13:15,935 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 22:13:15,964 INFO  io.prediction.tools.console.App$ [main] -              TextApp |    6 | 4MM9gXNr3LkMCSCfCoZcVzaWPJi1Gbpn2Hm1PiIvsSRVONiaSqhSRemUSnkaUZng | (all)
2015-04-21 22:13:15,989 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 22:13:16,002 INFO  io.prediction.tools.console.App$ [main] - Finished listing 6 app(s).
2015-04-21 22:13:28,164 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-21 22:13:28,166 INFO  io.prediction.tools.console.App$ [main] -     App Name: FinalDeployTest
2015-04-21 22:13:28,166 INFO  io.prediction.tools.console.App$ [main] -       App ID: 4
2015-04-21 22:13:28,167 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 22:13:34,831 INFO  io.prediction.tools.console.App$ [main] - Aborted.
2015-04-21 22:13:46,526 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-21 22:13:46,528 INFO  io.prediction.tools.console.App$ [main] -     App Name: FinalDeployTest
2015-04-21 22:13:46,528 INFO  io.prediction.tools.console.App$ [main] -       App ID: 4
2015-04-21 22:13:46,529 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 22:13:47,968 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:13:53,992 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_4...
2015-04-21 22:13:59,357 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 4
2015-04-21 22:13:59,373 INFO  io.prediction.tools.console.App$ [main] - Deleted app FinalDeployTest.
2015-04-21 22:13:59,475 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 22:14:10,541 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-21 22:14:10,543 INFO  io.prediction.tools.console.App$ [main] -     App Name: MyApp1
2015-04-21 22:14:10,544 INFO  io.prediction.tools.console.App$ [main] -       App ID: 1
2015-04-21 22:14:10,544 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 22:14:16,265 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:14:22,354 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_1...
2015-04-21 22:14:32,784 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 1
2015-04-21 22:14:32,806 INFO  io.prediction.tools.console.App$ [main] - Deleted app MyApp1.
2015-04-21 22:14:32,909 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 22:14:52,504 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-21 22:14:52,506 INFO  io.prediction.tools.console.App$ [main] -     App Name: MyApp2
2015-04-21 22:14:52,507 INFO  io.prediction.tools.console.App$ [main] -       App ID: 2
2015-04-21 22:14:52,508 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 22:14:54,642 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:14:55,676 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_2...
2015-04-21 22:15:01,520 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 2
2015-04-21 22:15:01,531 INFO  io.prediction.tools.console.App$ [main] - Deleted app MyApp2.
2015-04-21 22:15:01,642 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 22:15:12,418 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 22:15:12,474 INFO  io.prediction.tools.console.App$ [main] -               PTest1 |    3 | TO4tXr8YDZHdzWo3EH0KMtE8JwOP0GEz8gqVEpVB31GzNHD6ILSJNLXNlNrZNTBn | (all)
2015-04-21 22:15:12,498 INFO  io.prediction.tools.console.App$ [main] -              TextApp |    6 | 4MM9gXNr3LkMCSCfCoZcVzaWPJi1Gbpn2Hm1PiIvsSRVONiaSqhSRemUSnkaUZng | (all)
2015-04-21 22:15:12,509 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    5 | IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK | (all)
2015-04-21 22:15:12,510 INFO  io.prediction.tools.console.App$ [main] - Finished listing 3 app(s).
2015-04-21 22:15:23,941 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-21 22:15:23,943 INFO  io.prediction.tools.console.App$ [main] -     App Name: PTest1
2015-04-21 22:15:23,944 INFO  io.prediction.tools.console.App$ [main] -       App ID: 3
2015-04-21 22:15:23,945 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 22:15:26,214 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:15:37,186 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_3...
2015-04-21 22:15:42,552 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 3
2015-04-21 22:15:42,562 INFO  io.prediction.tools.console.App$ [main] - Deleted app PTest1.
2015-04-21 22:15:42,672 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 22:15:55,961 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-21 22:15:55,963 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp
2015-04-21 22:15:55,964 INFO  io.prediction.tools.console.App$ [main] -       App ID: 6
2015-04-21 22:15:55,964 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 22:15:58,135 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:15:59,129 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_6...
2015-04-21 22:16:04,483 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 6
2015-04-21 22:16:04,493 INFO  io.prediction.tools.console.App$ [main] - Deleted app TextApp.
2015-04-21 22:16:04,604 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 22:16:17,741 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-21 22:16:17,743 INFO  io.prediction.tools.console.App$ [main] -     App Name: TextApp1
2015-04-21 22:16:17,744 INFO  io.prediction.tools.console.App$ [main] -       App ID: 5
2015-04-21 22:16:17,744 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-21 22:16:20,469 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:16:21,504 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_5...
2015-04-21 22:16:27,048 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 5
2015-04-21 22:16:27,058 INFO  io.prediction.tools.console.App$ [main] - Deleted app TextApp1.
2015-04-21 22:16:27,168 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-21 22:17:29,191 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 22:17:29,194 INFO  io.prediction.tools.console.App$ [main] - Finished listing 0 app(s).
2015-04-21 22:17:48,968 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:17:55,032 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_7 doesn't exist yet. Creating now...
2015-04-21 22:18:05,513 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 7.
2015-04-21 22:18:05,535 INFO  io.prediction.tools.console.App$ [main] - Created new app:
2015-04-21 22:18:05,535 INFO  io.prediction.tools.console.App$ [main] -       Name: TextApp1
2015-04-21 22:18:05,536 INFO  io.prediction.tools.console.App$ [main] -         ID: 7
2015-04-21 22:18:05,536 INFO  io.prediction.tools.console.App$ [main] - Access Key: tTPBbTo25DDGz4fjwIauNAo8rQaED6bgd7XVidv7ytMucwcY1RIWpuHE5NXP2Nix
2015-04-21 22:19:19,357 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [hconnection-0x60c16548-shared--pool1-t3] - Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in hbase:meta for table: predictionio_eventdata:events_5, row=predictionio_eventdata:events_5,b\xB1Ms\xD0\xA6G\xD3\xFBC\xD3\xFB\xAD-\xAE\xEF\x00\x00\x01L\xDF\x90\xEC\xB9\xB7\xD2x\xAB\x16\xF9\x05\xDC,99999999999999
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:146)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1153)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1217)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:507)
	at org.apache.hadoop.hbase.client.AsyncProcess.logAndResubmit(AsyncProcess.java:717)
	at org.apache.hadoop.hbase.client.AsyncProcess.receiveMultiAction(AsyncProcess.java:813)
	at org.apache.hadoop.hbase.client.AsyncProcess.access$300(AsyncProcess.java:93)
	at org.apache.hadoop.hbase.client.AsyncProcess$1.run(AsyncProcess.java:560)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-21 22:19:19,376 ERROR akka.actor.LocalActorRef [EventServerSystem-akka.actor.default-dispatcher-11] - Error during processing of request HttpRequest(POST,http://localhost:7070/events.json?accessKey=IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK,List(Connection: keep-alive, Content-Type: application/json, Content-Length: 776, Accept-Encoding: identity, Host: localhost:7070),HttpEntity(application/json,{"properties": {"label": 11, "text": "From: rj@ri.cadre.com (Rob deFriesse)\nSubject: Can DES code be shipped to Canada?\nArticle-I.D.: fripp.1993Apr22.125402.27561\nReply-To: rj@ri.cadre.com\nOrganization: Cadre Technologies Inc.\nLines: 13\nNntp-Posting-Host: 192.9.200.19\n\nSomeone in Canada asked me to send him some public domain DES file\nencryption code I have.  Is it legal for me to send it?\n\nThanx.\n--\nEschew Obfuscation\n\nRob deFriesse                    Mail:  rj@ri.cadre.com\nCadr...),HTTP/1.1)
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: predictionio_eventdata:events_5: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:192)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:176)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:913)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:984)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:20:39,210 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 22:20:43,121 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:20:48,578 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-3] - Bound to /0.0.0.0:7070
2015-04-21 22:20:48,579 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-3] - Bound received. EventServer is ready.
2015-04-21 22:20:53,970 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [EventServerSystem-akka.actor.default-dispatcher-4] - Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in hbase:meta for table: predictionio_eventdata:events_5, row=predictionio_eventdata:events_5,b\xB1Ms\xD0\xA6G\xD3\xFBC\xD3\xFB\xAD-\xAE\xEF\x00\x00\x01L\xDF\x92[\xBD\x96[I\xED\x14\xCA\xA4?,99999999999999
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:146)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1153)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1217)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:20:54,003 ERROR akka.actor.LocalActorRef [EventServerSystem-akka.actor.default-dispatcher-2] - Error during processing of request HttpRequest(POST,http://localhost:7070/events.json?accessKey=IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK,List(Content-Type: application/json, Connection: keep-alive, Content-Length: 776, Accept-Encoding: identity, Host: localhost:7070),HttpEntity(application/json,{"entityType": "source", "entityId": 1, "properties": {"text": "From: rj@ri.cadre.com (Rob deFriesse)\nSubject: Can DES code be shipped to Canada?\nArticle-I.D.: fripp.1993Apr22.125402.27561\nReply-To: rj@ri.cadre.com\nOrganization: Cadre Technologies Inc.\nLines: 13\nNntp-Posting-Host: 192.9.200.19\n\nSomeone in Canada asked me to send him some public domain DES file\nencryption code I have.  Is it legal for me to send it?\n\nThanx.\n--\nEschew Obfuscation\n\nRob deFriesse                    Ma...),HTTP/1.1)
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: predictionio_eventdata:events_5: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:192)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:176)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:913)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:984)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:23:45,489 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [EventServerSystem-akka.actor.default-dispatcher-9] - Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in hbase:meta for table: predictionio_eventdata:events_5, row=predictionio_eventdata:events_5,b\xB1Ms\xD0\xA6G\xD3\xFBC\xD3\xFB\xAD-\xAE\xEF\x00\x00\x01L\xDF\x94\xFC\xBD\xAB\xBA\x5C\xFB\xE7%rf,99999999999999
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:146)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1153)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1217)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:23:45,493 ERROR akka.actor.LocalActorRef [EventServerSystem-akka.actor.default-dispatcher-5] - Error during processing of request HttpRequest(POST,http://localhost:7070/events.json?accessKey=IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK,List(Content-Type: application/json, Connection: keep-alive, Content-Length: 776, Accept-Encoding: identity, Host: localhost:7070),HttpEntity(application/json,{"entityType": "source", "event": "documents", "entityId": 1, "properties": {"text": "From: rj@ri.cadre.com (Rob deFriesse)\nSubject: Can DES code be shipped to Canada?\nArticle-I.D.: fripp.1993Apr22.125402.27561\nReply-To: rj@ri.cadre.com\nOrganization: Cadre Technologies Inc.\nLines: 13\nNntp-Posting-Host: 192.9.200.19\n\nSomeone in Canada asked me to send him some public domain DES file\nencryption code I have.  Is it legal for me to send it?\n\nThanx.\n--\nEschew Obfuscation\n\nRob deFriesse...),HTTP/1.1)
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: predictionio_eventdata:events_5: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:192)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:176)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:913)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:984)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:47:44,056 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 22:47:45,227 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:47:52,522 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-2] - Bound to /0.0.0.0:7070
2015-04-21 22:47:52,523 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-2] - Bound received. EventServer is ready.
2015-04-21 22:48:04,020 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [EventServerSystem-akka.actor.default-dispatcher-2] - Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in hbase:meta for table: predictionio_eventdata:events_5, row=predictionio_eventdata:events_5,b\xB1Ms\xD0\xA6G\xD3\xFBC\xD3\xFB\xAD-\xAE\xEF\x00\x00\x01L\xDF\xAB<\xE1\x85\xD4\xBB\x03\xA5\x9C\xFB',99999999999999
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:146)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1153)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1217)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:48:04,033 ERROR akka.actor.LocalActorRef [EventServerSystem-akka.actor.default-dispatcher-4] - Error during processing of request HttpRequest(POST,http://localhost:7070/events.json?accessKey=IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK,List(Connection: keep-alive, Content-Type: application/json, Content-Length: 776, Accept-Encoding: identity, Host: localhost:7070),HttpEntity(application/json,{"entityType": "source", "event": "documents", "properties": {"label": 11, "text": "From: rj@ri.cadre.com (Rob deFriesse)\nSubject: Can DES code be shipped to Canada?\nArticle-I.D.: fripp.1993Apr22.125402.27561\nReply-To: rj@ri.cadre.com\nOrganization: Cadre Technologies Inc.\nLines: 13\nNntp-Posting-Host: 192.9.200.19\n\nSomeone in Canada asked me to send him some public domain DES file\nencryption code I have.  Is it legal for me to send it?\n\nThanx.\n--\nEschew Obfuscation\n\nRob deFriesse  ...),HTTP/1.1)
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: predictionio_eventdata:events_5: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:192)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:176)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:913)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:984)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:48:48,310 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [EventServerSystem-akka.actor.default-dispatcher-9] - Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in hbase:meta for table: predictionio_eventdata:events_5, row=predictionio_eventdata:events_5,b\xB1Ms\xD0\xA6G\xD3\xFBC\xD3\xFB\xAD-\xAE\xEF\x00\x00\x01L\xDF\xAB\xEB\x1D\xACbDP\x977\x9Es,99999999999999
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:146)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1153)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1217)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:48:48,314 ERROR akka.actor.LocalActorRef [EventServerSystem-akka.actor.default-dispatcher-5] - Error during processing of request HttpRequest(POST,http://localhost:7070/events.json?accessKey=IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK,List(Content-Type: application/json, Connection: keep-alive, Content-Length: 776, Accept-Encoding: identity, Host: localhost:7070),HttpEntity(application/json,{"eventTime": "2015-04-22T05:48:48.285+0000", "event": "documents", "entityId": 1, "properties": {"text": "From: rj@ri.cadre.com (Rob deFriesse)\nSubject: Can DES code be shipped to Canada?\nArticle-I.D.: fripp.1993Apr22.125402.27561\nReply-To: rj@ri.cadre.com\nOrganization: Cadre Technologies Inc.\nLines: 13\nNntp-Posting-Host: 192.9.200.19\n\nSomeone in Canada asked me to send him some public domain DES file\nencryption code I have.  Is it legal for me to send it?\n\nThanx.\n--\nEschew Obfusca...),HTTP/1.1)
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: predictionio_eventdata:events_5: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:192)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:176)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:913)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:984)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:49:23,526 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 22:49:24,791 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 22:49:27,083 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-3] - Bound to /0.0.0.0:7070
2015-04-21 22:49:27,084 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-3] - Bound received. EventServer is ready.
2015-04-21 22:49:37,956 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [EventServerSystem-akka.actor.default-dispatcher-3] - Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in hbase:meta for table: predictionio_eventdata:events_5, row=predictionio_eventdata:events_5,b\xB1Ms\xD0\xA6G\xD3\xFBC\xD3\xFB\xAD-\xAE\xEF\x00\x00\x01L\xDF\xAC\xAB\xDD\xBA!\xC8\xDD:\x00\xAF\xE9,99999999999999
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:146)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1153)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1217)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:49:37,969 ERROR akka.actor.LocalActorRef [EventServerSystem-akka.actor.default-dispatcher-2] - Error during processing of request HttpRequest(POST,http://localhost:7070/events.json?accessKey=IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK,List(Connection: keep-alive, Content-Type: application/json, Content-Length: 776, Accept-Encoding: identity, Host: localhost:7070),HttpEntity(application/json,{"entityId": 1, "event": "documents", "properties": {"label": 11, "text": "From: rj@ri.cadre.com (Rob deFriesse)\nSubject: Can DES code be shipped to Canada?\nArticle-I.D.: fripp.1993Apr22.125402.27561\nReply-To: rj@ri.cadre.com\nOrganization: Cadre Technologies Inc.\nLines: 13\nNntp-Posting-Host: 192.9.200.19\n\nSomeone in Canada asked me to send him some public domain DES file\nencryption code I have.  Is it legal for me to send it?\n\nThanx.\n--\nEschew Obfuscation\n\nRob deFriesse           ...),HTTP/1.1)
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: predictionio_eventdata:events_5: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:192)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:176)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:913)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:984)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:56:07,377 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [EventServerSystem-akka.actor.default-dispatcher-9] - Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in hbase:meta for table: predictionio_eventdata:events_5, row=predictionio_eventdata:events_5,b\xB1Ms\xD0\xA6G\xD3\xFBC\xD3\xFB\xAD-\xAE\xEF\x00\x00\x01L\xDF\xB2\x9E?\xB7\xFA)K\x1D<\xD7\x15,99999999999999
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:146)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1153)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1217)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1105)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1062)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:365)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:310)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:964)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 22:56:07,381 ERROR akka.actor.LocalActorRef [EventServerSystem-akka.actor.default-dispatcher-5] - Error during processing of request HttpRequest(POST,http://localhost:7070/events.json?accessKey=IHeGYSNna0a1vNPnk9TNulOW1qzIhrI23JiMurUKK555ePCOzdCOFInZ0iS6cMdK,List(Content-Type: application/json, Connection: keep-alive, Content-Length: 776, Accept-Encoding: identity, Host: localhost:7070),HttpEntity(application/json,{"entityType": "source", "event": "documents", "entityId": 1, "eventTime": "2015-04-22T05:56:07.359+0000", "properties": {"label": 11, "text": "From: rj@ri.cadre.com (Rob deFriesse)\nSubject: Can DES code be shipped to Canada?\nArticle-I.D.: fripp.1993Apr22.125402.27561\nReply-To: rj@ri.cadre.com\nOrganization: Cadre Technologies Inc.\nLines: 13\nNntp-Posting-Host: 192.9.200.19\n\nSomeone in Canada asked me to send him some public domain DES file\nencryption code I have.  Is it legal for me to s...),HTTP/1.1)
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: predictionio_eventdata:events_5: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:192)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:176)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:913)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:984)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1252)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:910)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:108)
	at io.prediction.data.storage.hbase.HBLEvents$$anonfun$futureInsert$1.apply(HBLEvents.scala:105)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2015-04-21 23:02:25,081 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-21 23:02:26,652 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 23:02:28,990 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-4] - Bound to /0.0.0.0:7070
2015-04-21 23:02:28,991 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-4] - Bound received. EventServer is ready.
2015-04-21 23:05:06,126 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-21 23:05:06,252 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    7 | tTPBbTo25DDGz4fjwIauNAo8rQaED6bgd7XVidv7ytMucwcY1RIWpuHE5NXP2Nix | (all)
2015-04-21 23:05:06,253 INFO  io.prediction.tools.console.App$ [main] - Finished listing 1 app(s).
2015-04-21 23:05:17,469 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 23:05:17,515 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-21 23:05:17,515 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-21 23:05:17,516 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-21 23:05:17,517 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-21 23:05:31,631 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-21 23:05:31,632 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-21 23:05:31,639 INFO  io.prediction.tools.console.Console$ [main] - Found TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 23:05:31,640 INFO  io.prediction.tools.console.Console$ [main] - Found textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 23:05:31,648 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-21 23:05:33,249 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 23:05:33,352 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar
2015-04-21 23:05:33,435 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/TextManipulationEngine/target/scala-2.10/textmanipulationengine_2.10-0.1-SNAPSHOT.jar to file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar
2015-04-21 23:05:33,458 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d
2015-04-21 23:05:33,550 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-21 23:05:38,119 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/TextManipulationEngine/manifest.json
2015-04-21 23:05:39,771 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 23:05:39,900 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje f8de3b2e82df59a352b216bc539994f3f1bed16d () --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id 0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje --engine-version f8de3b2e82df59a352b216bc539994f3f1bed16d --engine-variant /Users/Marco/TextManipulationEngine/engine.json --verbosity 0
2015-04-21 23:05:41,930 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 23:05:42,959 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-21 23:05:43,070 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 23:05:43,085 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(7))
2015-04-21 23:05:43,086 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-21 23:05:43,087 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-21 23:05:43,088 INFO  io.prediction.controller.Engine [main] - Preparator params: (,PreparatorParams(1,2))
2015-04-21 23:05:43,094 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-21 23:05:43,095 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-21 23:05:44,884 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 23:05:45,120 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-139-9.calvisitor.1918.berkeley.edu:49747]
2015-04-21 23:05:46,677 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-21 23:05:46,678 INFO  io.prediction.controller.Engine$ [main] - DataSource: TextManipulationEngine.DataSource@47b269c4
2015-04-21 23:05:46,679 INFO  io.prediction.controller.Engine$ [main] - Preparator: TextManipulationEngine.Preparator@7c40ffef
2015-04-21 23:05:46,679 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(TextManipulationEngine.SupervisedAlgorithm@1e3df614)
2015-04-21 23:05:46,680 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-21 23:05:48,004 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.TrainingData does not support data sanity check. Skipping check.
2015-04-21 23:05:59,992 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.PreparedData does not support data sanity check. Skipping check.
2015-04-21 23:06:08,627 INFO  io.prediction.controller.Engine$ [main] - TextManipulationEngine.SupervisedModel does not support data sanity check. Skipping check.
2015-04-21 23:06:08,628 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-21 23:06:08,629 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUzfu2tqdR2XI-DnFBQn
2015-04-21 23:06:08,642 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-21 23:06:08,797 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-21 23:06:08,823 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-21 23:06:16,698 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUzfu2tqdR2XI-DnFBQn --jars file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/textmanipulationengine_2.10-0.1-SNAPSHOT.jar,file:/Users/Marco/.pio_store/engines/0IXnmkEdEZLz5zywAGvkm4DeXrC1oxje/f8de3b2e82df59a352b216bc539994f3f1bed16d/TextManipulationEngine-assembly-0.1-SNAPSHOT-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUzfu2tqdR2XI-DnFBQn --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-21 23:06:20,476 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-4] - Non-empty parameters supplied to TextManipulationEngine.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-21 23:06:20,885 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-21 23:06:21,052 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-139-9.calvisitor.1918.berkeley.edu:49789]
2015-04-21 23:06:21,349 WARN  org.apache.hadoop.util.NativeCodeLoader [pio-server-akka.actor.default-dispatcher-4] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-21 23:06:22,251 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-4] - Using persisted model
2015-04-21 23:06:22,253 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-4] - Loaded model TextManipulationEngine.SupervisedModel for algorithm TextManipulationEngine.SupervisedAlgorithm
2015-04-21 23:06:22,269 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-2] - Undeploying any existing engine instance at http://localhost:8000
2015-04-21 23:06:22,289 WARN  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-2] - Nothing at http://localhost:8000
2015-04-21 23:06:23,179 INFO  spray.can.server.HttpListener [pio-server-akka.actor.default-dispatcher-4] - Bound to localhost/127.0.0.1:8000
2015-04-21 23:06:23,180 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-5] - Bind successful. Ready to serve.
2015-04-22 00:50:57,326 WARN  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation [main-EventThread] - This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2015-04-22 12:42:53,146 WARN  org.elasticsearch.common [main] - Unable to get a valid mac address, will use a dummy address
2015-04-22 12:42:55,123 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-22 12:42:55,240 INFO  io.prediction.tools.console.App$ [main] -             TextApp1 |    7 | tTPBbTo25DDGz4fjwIauNAo8rQaED6bgd7XVidv7ytMucwcY1RIWpuHE5NXP2Nix | (all)
2015-04-22 12:42:55,241 INFO  io.prediction.tools.console.App$ [main] - Finished listing 1 app(s).
